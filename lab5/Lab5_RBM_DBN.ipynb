{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5_RBM_DBN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Restricted Boltzmann Machine και Deep Belief Network</b></h1>\n",
        "<p align=\"justify\">Στην συγκεκριμένη άσκηση θα μελετήσετε τον τρόπο λειτουργίας μιας <i>RBM (<a href=\"https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine\">Restricted Boltzmann Machine</a>)</i> καθώς και των <i>DBN (<a href=\"https://en.wikipedia.org/wiki/Deep_belief_network\">Deep Belief Network</a>)</i>, χρησιμοποιώντας το έτοιμο πρόγραμμα που σας δίνεται.Το συγκεκριμένο πρόγραμμα αξιοποιεί το <a href=\"https://en.wikipedia.org/wiki/MNIST_database\">dataset του <i>MNIST</i></a>, όπου είναι μια μεγάλη βάση δεδομένων με χειρόγραφα ψηφία που χρησιμοποιείται συνήθως για την εκπαίδευση διαφόρων συστημάτων επεξεργασίας εικόνας. Για την άσκηση, θα πρέπει να χρησιμοποιήσετε το αρχείο <i>mnist_original.mat</i>, το οποίο είναι διαθέσιμο από <a href=\"https://www.kaggle.com/datasets/avnishnish/mnist-original?resource=download\">εδώ</a>.</p>\n",
        "<p align=\"justify\">Μία αρκετά σημαντική εφαρμογή της <i>RBM</i> είναι η εξαγωγή χαρακτηριστικών (feature representation) από ένα dataset με σκοπό την αναπαράσταση της εισόδου (ορατοί νευρώνες) με ένα διάνυσμα μικρότερης διάστασης (κρυφοί νευρώνες). Στη συγκεκριμένη άσκηση θα συγκρίνετε την ακρίβεια ενός ταξινομητή ψηφίων με τη χρήση του αλγορίθμου <i>Logistic Regression</i>, όταν εκείνος δέχεται ως είσοδο το dataset (i) χωρίς να έχει υποστεί επεξεργασία από το <i>RBM</i>, (ii) αφου υποστεί επεξεργασία από το <i>RBM</i>, (iii) με τη χρήση <i>DBN</i>, δηλαδή δύο stacked <i>RBM</i>.</p>\n",
        "<p align=\"justify\"> Με βάση τον κώδικα που σας έχει δοθεί, καλείστε να απαντήσετε στα παρακάτω ερωτήματα:</p>\n",
        "<ul>\n",
        "<li>Να περιγράψετε σύντομα τον τρόπο λειτουργίας μιας <i>RBM</i>. Τι διαφορές έχει σε σχέση με μία <i> Μηχανή Boltzmann</i>;</li>\n",
        "<li>Ποια είναι η λογική των <i>DBN</i> και σε τι προβλήματα τα αξιοποιούμε;</li>\n",
        "<li>Να αναφέρετε τις βασικότερες εφαρμογές των <i>RBM</i> και <i>DBN</i>.</li>\n",
        "<li>Εκτός από <i>RBM</i>, τι άλλα μοντέλα μπορούν να χρησιμοποιηθούν για να δημιουργήσουν <i>DBN</i>.</li>\n",
        "<li>Συγκρίνετε τα αποτελέσματα της ταξινόμησης με τον αλγόριθμo <i>Logistic Regression</i> χωρίς τη χρήση <i>RBM</i> σε σχέση με τα αποτελέσματα της ταξινόμησης που έχει χρησιμοποιηθεί η <i>RBM</i> καθώς και με αυτή όπου χρησιμοποιούνται <i>RBM</i> και <i>DBN</i> για την εξαγωγή των χαρακτηριστικών. Τι παρατηρείτε ως προς την ακρίβεια των αποτελεσμάτων;</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "B5q7C447X8Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# source: https://devdreamz.com/question/905929-stacking-rbms-to-create-deep-belief-network-in-sklearn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from sklearn.base import clone\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def norm(arr):\n",
        "    arr = arr.astype(float)\n",
        "    arr -= arr.min()\n",
        "    arr /= arr.max()\n",
        "    return arr\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # load MNIST data set\n",
        "    mnist = loadmat(\"mnist-original.mat\")\n",
        "    X, Y = mnist[\"data\"].T, mnist[\"label\"][0]\n",
        "\n",
        "    # normalize inputs to 0-1 range\n",
        "    X = norm(X)\n",
        "\n",
        "    # split into train, validation, and test data sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X,       Y,       test_size=10000, random_state=0)\n",
        "    X_train, X_val,  Y_train, Y_val  = train_test_split(X_train, Y_train, test_size=10000, random_state=0)\n",
        "\n",
        "    # --------------------------------------------------------------------------------\n",
        "    # set hyperparameters\n",
        "\n",
        "    learning_rate = 0.02 \n",
        "    total_units   =  800 \n",
        "    total_epochs  =   50\n",
        "    batch_size    =  128\n",
        "\n",
        "    C = 100. # optimum for benchmark model according to sklearn docs: https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html#sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py)\n",
        "\n",
        "    # --------------------------------------------------------------------------------\n",
        "    # construct models\n",
        "\n",
        "    # RBM\n",
        "    rbm = BernoulliRBM(n_components=total_units, learning_rate=learning_rate, batch_size=batch_size, n_iter=total_epochs, verbose=1)\n",
        "\n",
        "    # \"output layer\"\n",
        "    logistic = LogisticRegression(C=C, solver='lbfgs', multi_class='multinomial', max_iter=200, verbose=1)\n",
        "\n",
        "    models = []\n",
        "    models.append(Pipeline(steps=[('logistic', clone(logistic))]))                                              # base model / benchmark\n",
        "    models.append(Pipeline(steps=[('rbm1', clone(rbm)), ('logistic', clone(logistic))]))                        # single RBM\n",
        "    models.append(Pipeline(steps=[('rbm1', clone(rbm)), ('rbm2', clone(rbm)), ('logistic', clone(logistic))]))  # RBM stack / DBN\n",
        "\n",
        "    # --------------------------------------------------------------------------------\n",
        "    # train and evaluate models\n",
        "\n",
        "    for model in models:\n",
        "        # train\n",
        "        model.fit(X_train, Y_train)\n",
        "\n",
        "        # evaluate using validation set\n",
        "        print(\"Model performance:\\n%s\\n\" % (\n",
        "            classification_report(Y_val, model.predict(X_val))))"
      ],
      "metadata": {
        "id": "Z6OQ6-N8ajZJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
