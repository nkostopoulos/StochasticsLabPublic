{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_9_DNS_Water_Torture).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUCLr2dsyWQ"
      },
      "source": [
        "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
        "\n",
        "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab9/Lab_theory.pdf\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που ζητάει το διαχωρισμό ονομάτων DNS σε <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
        "\n",
        "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος www.ntua.gr είναι το <i>www</i>, ενώ το prefix του ονόματος dolly.netmode.ece.ntua.gr είναι το <i>dolly</i>.</p>\n",
        "\n",
        "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/invalid_training.txt\">invalid_training.txt</a>). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
        "\n",
        "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
        "<ul>\n",
        "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
        "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
        "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab9/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
        "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
        "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
        "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
        "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
        "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
        "</ul>\n",
        "\n",
        "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
        "<ul>\n",
        "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
        "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab9/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_plJQ1Z2i5M",
        "outputId": "958a21cc-f0ae-47dd-cb02-313d9b5ae176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
        "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
        "\n",
        "def load_file(file_name):\n",
        "    fd = open(file_name, \"r\")\n",
        "    my_set = set()\n",
        "    for prefix in fd:\n",
        "        prefix = prefix.rstrip()\n",
        "        my_set.add(prefix)\n",
        "    return my_set\n",
        "\n",
        "def calculate_probabilities(dataset):\n",
        "    stats = dict()\n",
        "    for index in range(0, 7):\n",
        "        stats[index] = dict()\n",
        "    for prefix in dataset:\n",
        "        features = handle_name(prefix)\n",
        "        for index in range(0, 7):\n",
        "            try:\n",
        "                stats[index][features[index]] += 1\n",
        "            except:\n",
        "                stats[index][features[index]] = 1\n",
        "\n",
        "    dataset_size = len(dataset)    \n",
        "    for index in range(0, 7):\n",
        "        for key in stats[index]:\n",
        "            stats[index][key] /= dataset_size\n",
        "    return stats\n",
        "\n",
        "def handle_name(prefix):\n",
        "    total_length = len(prefix)\n",
        "    total_digits, max_numeric_sequence = numeric(prefix)\n",
        "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
        "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
        "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
        "\n",
        "def vowels(prefix):\n",
        "    total_vowels = 0\n",
        "    vowels_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
        "            total_vowels += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            vowels_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    vowels_sequence.append(current_sequence)\n",
        "    max_vowels_sequence = max(vowels_sequence)\n",
        "    return total_vowels, max_vowels_sequence\n",
        "\n",
        "def consonants(prefix):\n",
        "    total_consonants = 0\n",
        "    consonants_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
        "            total_consonants += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            consonants_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    consonants_sequence.append(current_sequence)\n",
        "    max_consonants_sequence = max(consonants_sequence)\n",
        "    return total_consonants, max_consonants_sequence\n",
        "\n",
        "def numeric(prefix):\n",
        "    total_digits = 0\n",
        "    numeric_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char.isdigit() == True:\n",
        "            total_digits += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            numeric_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    numeric_sequence.append(current_sequence)\n",
        "    max_numeric_sequence = max(numeric_sequence)\n",
        "    return total_digits, max_numeric_sequence\n",
        "            \n",
        "def find_prob(prefix, stats, fd):\n",
        "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
        "    try:\n",
        "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
        "    except:\n",
        "        prob = 0\n",
        "        fd.write(prefix + \"\\n\")\n",
        "    return prob\n",
        "\n",
        "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
        "    misclassifications = 0\n",
        "    names_processed = 0\n",
        "    for prefix in test_set:\n",
        "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
        "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
        "        if valid_prob != 0 and invalid_prob != 0:\n",
        "            names_processed += 1\n",
        "            if category == \"valid\" and valid_prob < invalid_prob:\n",
        "                misclassifications += 1\n",
        "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
        "                misclassifications += 1\n",
        "    return misclassifications, names_processed\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load valid names training set\n",
        "    valid_names_training = load_file(\"./valid_training.txt\")\n",
        "    # Load valid names test set\n",
        "    valid_names_test = load_file(\"./valid_test.txt\")\n",
        "    # Load invalid names training set\n",
        "    invalid_names_training = load_file(\"./invalid_training.txt\")\n",
        "    # Load invalid names test set\n",
        "    invalid_names_test = load_file(\"./invalid_test.txt\") \n",
        "\n",
        "    valid_stats = calculate_probabilities(valid_names_training)\n",
        "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
        "\n",
        "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
        "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
        "\n",
        "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
        "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
            "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n"
          ]
        }
      ]
    }
  ]
}